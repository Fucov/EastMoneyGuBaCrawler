#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç†æ± ç®¡ç†å™¨ - ä½¿ç”¨Redisç¼“å­˜ä»£ç†
é‡æ„è‡ª proxy_pool.pyï¼Œä¼˜åŒ–ä¸ºç”Ÿäº§ç¯å¢ƒä½¿ç”¨
"""

import requests
import re
import time
import json
import redis
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Optional, Dict
import random


class ProxyManager:
    """
    ä»£ç†æ± ç®¡ç†å™¨ï¼ˆRedisç‰ˆæœ¬ï¼‰

    ç‰¹æ€§ï¼š
    - RedisæŒä¹…åŒ–ä»£ç†
    - è‡ªåŠ¨éªŒè¯å’Œè¯„åˆ†
    - å¤±æ•ˆè‡ªåŠ¨ç§»é™¤
    - ä½äºé˜ˆå€¼è‡ªåŠ¨è¡¥å……
    """

    def __init__(
        self,
        redis_host="localhost",
        redis_port=6379,
        redis_password=None,
        redis_db=0,
        cache_key="guba:proxies:valid",
        target_url="https://guba.eastmoney.com/",
        min_threshold=5,
    ):
        """
        åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨

        Args:
            redis_host: Redisä¸»æœº
            redis_port: Redisç«¯å£
            redis_password: Rediså¯†ç ï¼ˆNoneè¡¨ç¤ºæ— å¯†ç ï¼‰
            redis_db: Redisæ•°æ®åº“ç¼–å·
            cache_key: ç¼“å­˜key
            target_url: éªŒè¯ç›®æ ‡URL
            min_threshold: æœ€å°ä»£ç†é˜ˆå€¼
        """
        # Redisè¿æ¥
        self.redis_client = redis.StrictRedis(
            host=redis_host,
            port=redis_port,
            password=redis_password if redis_password else None,
            db=redis_db,
            decode_responses=True,
        )

        self.cache_key = cache_key
        self.test_url = target_url
        self.timeout = 3
        self.min_threshold = min_threshold

        # ä»£ç†æºé…ç½®
        self.sources = [
            {
                "type": "text",
                "url": "http://api.89ip.cn/tqdl.html?api=1&num=60",
                "name": "89ip-API",
            },
            {
                "type": "text",
                "url": "https://proxy.scdn.io/text.php",
                "name": "proxy.scdn.io",
            },
        ]

    def count(self) -> int:
        """è·å–å½“å‰æœ‰æ•ˆä»£ç†æ•°é‡"""
        return self.redis_client.hlen(self.cache_key)

    def get_all(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰ä»£ç†

        Returns:
            [{'proxy': 'http://...', 'score': 95}, ...]
        """
        proxies = []
        for proxy_url, score in self.redis_client.hgetall(self.cache_key).items():
            proxies.append({"proxy": proxy_url, "score": int(score)})

        # æŒ‰è¯„åˆ†æ’åº
        proxies.sort(key=lambda x: x["score"], reverse=True)
        return proxies

    def get_random_proxy(self) -> Optional[Dict]:
        """
        éšæœºè·å–ä¸€ä¸ªä»£ç†

        Returns:
            {'http': 'http://...', 'https': 'http://...'} æˆ– None
        """
        # æ£€æŸ¥é˜ˆå€¼
        if self.count() < self.min_threshold:
            print(f"âš ï¸ ä»£ç†æ± ä¸è¶³({self.count()}ä¸ª)ï¼Œè§¦å‘è‡ªåŠ¨è¡¥å……...")
            self.refill_pool()

        proxies = self.get_all()
        if not proxies:
            return None

        # ä»é«˜åˆ†ä»£ç†ä¸­éšæœºé€‰æ‹©
        if len(proxies) > 10:
            top_half = proxies[: max(1, len(proxies) // 2)]
            selected = random.choice(top_half)
        else:
            selected = random.choice(proxies)

        proxy_url = selected["proxy"]
        return {"http": proxy_url, "https": proxy_url}

    def add_proxy(self, proxy_url: str, score: int = 100):
        """æ·»åŠ ä»£ç†åˆ°Redis"""
        self.redis_client.hset(self.cache_key, proxy_url, score)

    def remove_proxy(self, proxy_dict: Dict):
        """ç§»é™¤å¤±æ•ˆä»£ç†"""
        if not proxy_dict:
            return

        proxy_url = proxy_dict.get("http")
        if proxy_url:
            self.redis_client.hdel(self.cache_key, proxy_url)

    def update_score(self, proxy_url: str, success: bool):
        """æ›´æ–°ä»£ç†è¯„åˆ†"""
        current_score = self.redis_client.hget(self.cache_key, proxy_url)
        if current_score is None:
            return

        score = int(current_score)

        if success:
            score = min(100, score + 5)
        else:
            score = max(0, score - 10)

        if score < 30:
            # è¯„åˆ†è¿‡ä½ï¼Œç§»é™¤
            self.redis_client.hdel(self.cache_key, proxy_url)
        else:
            self.redis_client.hset(self.cache_key, proxy_url, score)

    def fetch_raw_ips(self, max_per_source: int = 100) -> List[str]:
        """ä»æºç«™æŠ“å–åŸå§‹IPåˆ—è¡¨"""
        raw_list = []
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }

        print("ğŸ“¡ å¼€å§‹æŠ“å–ä»£ç†æº...")
        for source in self.sources:
            try:
                url = source["url"]
                name = source["name"]
                source_type = source["type"]
                params = source.get("params", {})

                if source_type == "zdaili_api":
                    resp = requests.get(url, params=params, headers=headers, timeout=10)
                    time.sleep(10)
                else:
                    resp = requests.get(url, headers=headers, timeout=10)

                # è§£æå“åº”
                if source_type == "zdaili_api":
                    try:
                        data = resp.json()
                        code = str(data.get("code"))
                        if code == "10001":
                            proxy_list = data.get("data", {}).get("proxy_list", [])
                            for proxy_info in proxy_list:
                                ip = proxy_info.get("ip")
                                port = proxy_info.get("port")
                                if ip and port:
                                    raw_list.append(f"{ip}:{port}")
                            print(f"  âœ“ {name}: {len(proxy_list)}ä¸ª")
                        else:
                            print(f"  âœ— {name}: {data.get('msg')}")
                    except:
                        pass
                else:
                    # æ–‡æœ¬æ ¼å¼
                    found = re.findall(r"\d+\.\d+\.\d+\.\d+[:ï¼š]\d+", resp.text)
                    raw_list.extend(found)
                    print(f"  âœ“ {name}: {len(found)}ä¸ª")

            except Exception as e:
                print(f"  âœ— {source['name']}: {e}")

        unique_list = list(set(raw_list))
        print(f"ğŸ“Š å…±æŠ“å– {len(unique_list)} ä¸ªå”¯ä¸€ä»£ç†\n")
        return unique_list

    def verify_proxy(self, proxy_str: str) -> Optional[str]:
        """éªŒè¯ä»£ç†æ˜¯å¦å¯ç”¨"""
        proxy_url = proxy_str.replace("ï¼š", ":")
        if not proxy_url.startswith("http"):
            proxy_url = "http://" + proxy_url

        proxies = {"http": proxy_url, "https": proxy_url}

        try:
            start_time = time.time()
            resp = requests.get(
                self.test_url,
                proxies=proxies,
                timeout=self.timeout,
                headers={"User-Agent": "Mozilla/5.0"},
            )
            response_time = time.time() - start_time

            if resp.status_code == 200:
                score = max(100 - int(response_time * 20), 50)
                print(f" âœ“ {proxy_url} (å“åº”{response_time:.2f}s, è¯„åˆ†{score})")
                return proxy_url, score
        except:
            pass

        return None

    def build_pool(self, max_workers: int = 30, max_per_source: int = 100):
        """åˆå§‹å»ºç«‹ä»£ç†æ± """
        raw_ips = self.fetch_raw_ips(max_per_source)
        print(f"ğŸ” å¼€å§‹éªŒè¯ï¼ˆ{max_workers}çº¿ç¨‹ï¼‰...\n")

        valid_count = 0
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_proxy = {
                executor.submit(self.verify_proxy, ip): ip for ip in raw_ips
            }

            for future in as_completed(future_to_proxy):
                result = future.result()
                if result:
                    proxy_url, score = result
                    self.add_proxy(proxy_url, score)
                    valid_count += 1

        print(f"\nâœ… éªŒè¯å®Œæˆï¼Œè·å¾— {valid_count} ä¸ªæœ‰æ•ˆä»£ç†")
        return valid_count

    def refill_pool(self, target_count: int = 20, max_workers: int = 30):
        """è¡¥å……ä»£ç†æ± """
        current = self.count()
        print(f"ğŸ”„ ä»£ç†æ± è¡¥å……ï¼ˆå½“å‰{current}ä¸ªï¼Œç›®æ ‡{target_count}ä¸ªï¼‰")

        raw_ips = self.fetch_raw_ips(max_per_source=100)

        # è¿‡æ»¤å·²å­˜åœ¨çš„
        existing = set(self.redis_client.hkeys(self.cache_key))
        new_ips = [ip for ip in raw_ips if f"http://{ip}" not in existing]

        print(f"ğŸ“Š è¿‡æ»¤å {len(new_ips)} ä¸ªæ–°å€™é€‰")

        added = 0
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_proxy = {
                executor.submit(self.verify_proxy, ip): ip for ip in new_ips
            }

            for future in as_completed(future_to_proxy):
                result = future.result()
                if result:
                    proxy_url, score = result
                    self.add_proxy(proxy_url, score)
                    added += 1

                    if self.count() >= target_count:
                        break

        print(f"âœ… è¡¥å……å®Œæˆï¼Œæ–°å¢{added}ä¸ªï¼Œå½“å‰å…±{self.count()}ä¸ª\n")

    def revalidate_pool(self, max_workers: int = 20):
        """é‡æ–°éªŒè¯æ‰€æœ‰ä»£ç†"""
        proxies = self.get_all()
        print(f"ğŸ”„ é‡æ–°éªŒè¯ {len(proxies)} ä¸ªä»£ç†...")

        # æ¸…ç©º
        self.redis_client.delete(self.cache_key)

        valid_count = 0
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_proxy = {
                executor.submit(self.verify_proxy, p["proxy"].replace("http://", "")): p
                for p in proxies
            }

            for future in as_completed(future_to_proxy):
                result = future.result()
                if result:
                    proxy_url, score = result
                    self.add_proxy(proxy_url, score)
                    valid_count += 1

        print(f"âœ… éªŒè¯å®Œæˆï¼Œä¿ç•™ {valid_count} ä¸ªæœ‰æ•ˆä»£ç†\n")

    def save_to_file(self, filename: str = "valid_proxies.txt"):
        """
        å°†Redisä¸­çš„ä»£ç†å¯¼å‡ºåˆ°æ–‡ä»¶å¤‡ä»½

        Args:
            filename: æ–‡ä»¶å
        """
        proxies = self.get_all()
        with open(filename, "w") as f:
            for proxy in proxies:
                f.write(f"{proxy['proxy']} # è¯„åˆ†:{proxy['score']}\n")
        print(f"ğŸ’¾ å·²ä¿å­˜{len(proxies)}ä¸ªä»£ç†åˆ° {filename}")

    def load_from_file(self, filename: str = "valid_proxies.txt") -> bool:
        """
        ä»æ–‡ä»¶åŠ è½½ä»£ç†åˆ°Redis

        Args:
            filename: æ–‡ä»¶å

        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½ï¼ˆè‡³å°‘1ä¸ªä»£ç†ï¼‰
        """
        try:
            loaded_count = 0
            with open(filename, "r") as f:
                for line in f:
                    if line.strip() and not line.startswith("#"):
                        proxy = line.split("#")[0].strip()
                        if proxy:
                            # è§£æè¯„åˆ†
                            score = 100
                            if "è¯„åˆ†:" in line:
                                try:
                                    score = int(line.split("è¯„åˆ†:")[1].strip())
                                except:
                                    pass
                            self.add_proxy(proxy, score)
                            loaded_count += 1

            if loaded_count > 0:
                print(f"ğŸ“‚ ä» {filename} åŠ è½½äº† {loaded_count} ä¸ªä»£ç†")
                return True
            else:
                print(f"âš ï¸ {filename} æ–‡ä»¶ä¸ºç©ºï¼Œå°†é‡æ–°æŠ“å–")
                return False
        except FileNotFoundError:
            print(f"âš ï¸ æ–‡ä»¶ {filename} ä¸å­˜åœ¨")
            return False


if __name__ == "__main__":
    # æµ‹è¯•
    print("=" * 60)
    print("ä»£ç†æ± ç®¡ç†å™¨æµ‹è¯•ï¼ˆRedisç‰ˆæœ¬ï¼‰")
    print("=" * 60)

    manager = ProxyManager()

    # æµ‹è¯•Redisè¿æ¥
    try:
        manager.redis_client.ping()
        print("âœ… Redisè¿æ¥æˆåŠŸ\n")
    except:
        print("âŒ Redisè¿æ¥å¤±è´¥ï¼Œè¯·å¯åŠ¨RedisæœåŠ¡\n")
        exit(1)

    # å»ºç«‹ä»£ç†æ± 
    manager.build_pool(max_workers=30, max_per_source=50)

    # è·å–ä»£ç†
    print(f"\nå½“å‰ä»£ç†æ•°: {manager.count()}")
    proxy = manager.get_random_proxy()
    print(f"éšæœºä»£ç†: {proxy}")
